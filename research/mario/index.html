<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Deep Learning for Retinal Degeneration Assessment: The MARIO AMD Progression Challenge | Rachid. Zeghlache</title>
<meta name=description content="A comprehensive analysis of the MARIO challenge held at MICCAI 2024, evaluating AI algorithms for detecting and monitoring age-related macular degeneration progression using OCT imaging."><link rel=stylesheet href=https://youvenz.github.io/css/main.css><link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Lora:ital,wght@0,400;0,700;1,400&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css></head><body class="page research"><div class=site-container><header class=site-header><div class=container><div class=header-content><div class=logo><a href=https://youvenz.github.io/><h1 class=site-title>Rachid. Zeghlache</h1></a></div><nav class=main-nav><ul class=nav-menu><li><a href=https://youvenz.github.io/>Home</a></li><li><a href=https://youvenz.github.io/research/>Research</a></li><li><a href=https://youvenz.github.io/publications/>Publications</a></li><li><a href=https://youvenz.github.io/teaching/>Teaching</a></li><li><a href=https://youvenz.github.io/cv/>CV</a></li><li><a href=https://youvenz.github.io/talk/>Talk</a></li><li><a href=https://youvenz.github.io/contact/>Contact</a></li></ul></nav><button class=menu-toggle aria-label="Toggle menu">
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div></div></header><main id=content><div class=research-single><div class=research-header><h1>Deep Learning for Retinal Degeneration Assessment: The MARIO AMD Progression Challenge</h1><div class=research-meta><div class=meta-item><span class=meta-label>Date:</span>
<span class=meta-value>October 10, 2024</span></div><div class=meta-item><span class=meta-label>Authors:</span>
<span class=meta-value>Rachid Zeghlache and al.</span></div><div class=meta-item><span class=meta-label>Funding:</span>
<span class=meta-value>French National Research Agency (ANR) - Evired project RHU program - ANR-18-RHUS-0008</span></div><div class="meta-item tags"><span class=meta-label>Tags:</span><div class=meta-tags><span class=tag>deep learning</span>
<span class=tag>medical imaging</span>
<span class=tag>AMD</span>
<span class=tag>OCT</span>
<span class=tag>retinal imaging</span>
<span class=tag>computer vision</span>
<span class=tag>MICCAI challenge</span></div></div></div></div><div class=featured-image><img src=/images/thumbnails/square_image_mario.png alt="Deep Learning for Retinal Degeneration Assessment: The MARIO AMD Progression Challenge"></div><div class=research-content><h2 id=project-overview>Project Overview</h2><p>The MARIO (Monitoring Age-Related macular degeneration with Intelligent Ophthalmology) challenge represents a landmark initiative in applying artificial intelligence to retinal disease monitoring. Held at MICCAI 2024 in Marrakesh, this challenge specifically addressed the critical need for automated detection and monitoring of age-related macular degeneration (AMD) through optical coherence tomography (OCT) image analysis.</p><h2 id=research-objectives>Research Objectives</h2><p>The challenge focused on two primary computational tasks:</p><ol><li><strong>Task 1: Evolution Classification</strong> - Classify changes between two consecutive 2D OCT B-scans to detect disease activity modifications</li><li><strong>Task 2: Progression Prediction</strong> - Predict future AMD evolution over a three-month period for patients undergoing anti-VEGF therapy</li></ol><h2 id=dataset-and-methodology>Dataset and Methodology</h2><p>The challenge utilized a unique multi-modal dataset comprising:</p><ul><li><strong>Primary Dataset</strong>: 136 patients from Brest, France (training and testing)</li><li><strong>Auxiliary Dataset</strong>: 5 patients from Algeria (domain adaptation evaluation)</li><li><strong>Data Types</strong>: OCT B-scans, infrared localizer images, and clinical metadata</li><li><strong>Annotation</strong>: Expert ophthalmologist annotations with inter-annotator agreement analysis</li></ul><h2 id=key-findings>Key Findings</h2><h3 id=challenge-results>Challenge Results</h3><ul><li><strong>35 teams participated</strong> with 12 finalists presenting their methodologies</li><li><strong>Task 1 Success</strong>: AI algorithms demonstrated performance comparable to physicians in measuring AMD progression</li><li><strong>Task 2 Challenges</strong>: Prediction of future evolution remains difficult, with no team achieving fully satisfactory results</li></ul><h3 id=technical-innovations>Technical Innovations</h3><ul><li><strong>Foundation Models</strong>: Teams using RetFound (retinal-specific pre-trained models) showed superior performance</li><li><strong>Multi-modal Learning</strong>: Integration of OCT images, localizer data, and clinical variables improved outcomes</li><li><strong>Domain Adaptation</strong>: Significant performance variations observed between European and African datasets</li></ul><h2 id=clinical-significance>Clinical Significance</h2><p>The challenge addressed a critical gap in longitudinal monitoring of neovascular activity in AMD patients receiving anti-VEGF therapy. Current treatment paradigms (fixed-interval, PRN, treat-and-extend) require accurate assessment of disease activity markers, particularly fluid presence and evolution patterns.</p><h2 id=collaborators>Collaborators</h2><ul><li><strong>LaTIM UMR 1101, Inserm</strong> - Primary organizing institution</li><li><strong>CHU Brest</strong> - Clinical data provider and expert annotations</li><li><strong>Lazouni Ophthalmology Clinic, Algeria</strong> - Domain adaptation dataset</li><li><strong>35 International Teams</strong> - Algorithm development and validation</li></ul><h2 id=publications>Publications</h2><ol><li>Zeghlache, R., et al. (2025). &ldquo;Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO AMD Progression Challenge.&rdquo; arXiv:2506.02976v2 [cs.CV].</li></ol><h2 id=technical-achievements>Technical Achievements</h2><h3 id=winning-methodologies>Winning Methodologies</h3><ul><li><strong>MIPLAB Team</strong>: Multi-modal fusion approach combining OCT, localizer images, and clinical variables</li><li><strong>yyama Team</strong>: MaxViT architecture with innovative image concatenation strategies</li><li><strong>MIC Group 6</strong>: Siamese networks with foundation model encoders</li></ul><h3 id=performance-metrics>Performance Metrics</h3><ul><li><strong>Task 1</strong>: F1-scores ranging from 0.691 to 0.858 across teams</li><li><strong>Task 2</strong>: Quadratic Weighted Kappa scores indicating substantial room for improvement</li><li><strong>Cross-dataset Performance</strong>: Notable degradation when applying models to different populations/devices</li></ul><h2 id=future-directions>Future Directions</h2><p>The challenge identified several areas for advancement:</p><ol><li><strong>Enhanced Generative Approaches</strong>: Better synthetic data generation for data augmentation</li><li><strong>Improved Multi-modal Integration</strong>: Standardized frameworks for combining diverse data types</li><li><strong>Domain Adaptation</strong>: Robust methods for handling population and device shifts</li><li><strong>Temporal Modeling</strong>: Advanced architectures for longitudinal disease progression</li><li><strong>Clinical Integration</strong>: Incorporation of treatment history and patient-specific factors</li></ol><h2 id=funding>Funding</h2><p>This research was conducted within the Evired project framework, funded by the French National Research Agency (ANR) under the RHU program, with support from the French government&rsquo;s &ldquo;Investissements d&rsquo;Avenir&rdquo; program (ANR-18-RHUS-0008).</p><h2 id=data-availability>Data Availability</h2><p>The Brest dataset has been made publicly available via Zenodo to facilitate reproducible research and continued algorithm development in the AMD monitoring domain.</p></div><div class=research-navigation><a class=prev-link href=/research/neural_ode_disease_progression/><span class=nav-label>Previous Research</span>
<span class=nav-title>Neural ODEs for Disease Progression Modeling</span></a></div></div></main><footer class=site-footer><div class=container><div class=footer-content><div class=footer-info><p>Â© 2025 Rachid. Zeghlache. All rights reserved.</p></div><div class=social-links><a href=https://x.com/ZYouven target=_blank rel=noopener aria-label=Twitter><i class="fab fa-twitter"></i>
</a><a href=https://www.linkedin.com/in/rachid-youven-zeghlache-795816183/ target=_blank rel=noopener aria-label=LinkedIn><i class="fab fa-linkedin"></i>
</a><a href=https://github.com/YouvenZ/ target=_blank rel=noopener aria-label=GitHub><i class="fab fa-github"></i>
</a><a href="https://scholar.google.com/citations?user=iWgYuY0AAAAJ&amp;hl=en" target=_blank rel=noopener aria-label="Google Scholar"><i class="fab fa-google"></i></a></div></div></div></footer></div><script src=https://youvenz.github.io/js/main.js></script></body></html>